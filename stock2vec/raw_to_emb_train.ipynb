{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run get_vocab.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "data_dir = './Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gt_val</th>\n",
       "      <th>gt_sym</th>\n",
       "      <th>lt_val</th>\n",
       "      <th>lt_sym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>[0.8706872487325694, 0.6136363069873223, 0.495...</td>\n",
       "      <td>['PHUN', 'NBSE', 'OCGN', 'BOXL', 'KTOV', 'BTAI...</td>\n",
       "      <td>([-0.3673469462229876, -0.26984126683776033, -...</td>\n",
       "      <td>['SESN', 'CCCL', 'SELB', 'ATRA', 'LTRPB', 'SFE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>[1.0265407170232148, 0.6296295293346674, 0.327...</td>\n",
       "      <td>['PHUN', 'CGIX', 'EPZM', 'DRRX', 'TMDI', 'SUNW...</td>\n",
       "      <td>([-0.1925466206425025, -0.1573959338395985, -0...</td>\n",
       "      <td>['RBZ', 'TVIX', 'ELGX', 'ZBIO', 'BOXL', 'SQQQ'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>[1.612167143201626, 0.4767024881329074, 0.4323...</td>\n",
       "      <td>['AXSM', 'ADXS', 'INSM', 'SAGE', 'PDSB', 'RBZ'...</td>\n",
       "      <td>([-0.5494845390218467, -0.5019011841153402, -0...</td>\n",
       "      <td>['CFRX', 'LJPC', 'NHTC', 'AXGN', 'CUTR', 'GSUM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>[1.0444301396706108, 0.4708994668947917, 0.364...</td>\n",
       "      <td>['CLPS', 'MBOT', 'YI', 'PHUN', 'PLXP', 'ORGO',...</td>\n",
       "      <td>([-0.7539682502138672, -0.2285713847802603, -0...</td>\n",
       "      <td>['PROF', 'BRPAR', 'CFRX', 'ECOR', 'GWGH', 'AEY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-09</td>\n",
       "      <td>[5.127232220625748, 1.5882352941176472, 1.4078...</td>\n",
       "      <td>['ORGO', 'PHUN', 'WINS', 'SAEX', 'VIVE', 'ATOS...</td>\n",
       "      <td>([-0.2503917207560298, -0.16546764132411507, -...</td>\n",
       "      <td>['SGH', 'MBOT', 'CLPS', 'AXSM', 'SGMO', 'MRIN'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             gt_val  \\\n",
       "0  2019-01-03  [0.8706872487325694, 0.6136363069873223, 0.495...   \n",
       "1  2019-01-04  [1.0265407170232148, 0.6296295293346674, 0.327...   \n",
       "2  2019-01-07  [1.612167143201626, 0.4767024881329074, 0.4323...   \n",
       "3  2019-01-08  [1.0444301396706108, 0.4708994668947917, 0.364...   \n",
       "4  2019-01-09  [5.127232220625748, 1.5882352941176472, 1.4078...   \n",
       "\n",
       "                                              gt_sym  \\\n",
       "0  ['PHUN', 'NBSE', 'OCGN', 'BOXL', 'KTOV', 'BTAI...   \n",
       "1  ['PHUN', 'CGIX', 'EPZM', 'DRRX', 'TMDI', 'SUNW...   \n",
       "2  ['AXSM', 'ADXS', 'INSM', 'SAGE', 'PDSB', 'RBZ'...   \n",
       "3  ['CLPS', 'MBOT', 'YI', 'PHUN', 'PLXP', 'ORGO',...   \n",
       "4  ['ORGO', 'PHUN', 'WINS', 'SAEX', 'VIVE', 'ATOS...   \n",
       "\n",
       "                                              lt_val  \\\n",
       "0  ([-0.3673469462229876, -0.26984126683776033, -...   \n",
       "1  ([-0.1925466206425025, -0.1573959338395985, -0...   \n",
       "2  ([-0.5494845390218467, -0.5019011841153402, -0...   \n",
       "3  ([-0.7539682502138672, -0.2285713847802603, -0...   \n",
       "4  ([-0.2503917207560298, -0.16546764132411507, -...   \n",
       "\n",
       "                                              lt_sym  \n",
       "0  ['SESN', 'CCCL', 'SELB', 'ATRA', 'LTRPB', 'SFE...  \n",
       "1  ['RBZ', 'TVIX', 'ELGX', 'ZBIO', 'BOXL', 'SQQQ'...  \n",
       "2  ['CFRX', 'LJPC', 'NHTC', 'AXGN', 'CUTR', 'GSUM...  \n",
       "3  ['PROF', 'BRPAR', 'CFRX', 'ECOR', 'GWGH', 'AEY...  \n",
       "4  ['SGH', 'MBOT', 'CLPS', 'AXSM', 'SGMO', 'MRIN'...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data and preview\n",
    "\n",
    "rawdata = pd.read_csv(data_dir + './data.csv')\n",
    "rawdata[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of word in a long sentence\n",
    "n_top = 500\n",
    "\n",
    "# number of word in a sentence of embedding training set\n",
    "n_similar = 20\n",
    "\n",
    "# number of sentence in a sentence of embedding training set\n",
    "n_sentence = 50000 \n",
    "\n",
    "# function to get top 500 and bottom 500 for each day\n",
    "def get_top(x, n=n_top):\n",
    "    return(x.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\",\", \"\").split(\" \")[0:n])\n",
    "\n",
    "# function to make the long sentence shorter, from 500 to 20\n",
    "def get_similar(x, n=n_similar):\n",
    "    ind = np.random.choice(len(x), n, replace=False)\n",
    "    return( [x[i] for i in ind] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of unique long sentences\n",
    "\n",
    "gt_top_list = [get_top(x, n_top) for x in rawdata.gt_sym]\n",
    "lt_top_list = [get_top(x, n_top) for x in rawdata.lt_sym]\n",
    "total_list = gt_top_list+lt_top_list\n",
    "len(total_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MDGL',\n",
       " 'RAND',\n",
       " 'CCCL',\n",
       " 'VOXX',\n",
       " 'RIOT',\n",
       " 'MBCN',\n",
       " 'ATLO',\n",
       " 'SRRK',\n",
       " 'JRJC',\n",
       " 'BVSN',\n",
       " 'THMO',\n",
       " 'LIND',\n",
       " 'NEWA',\n",
       " 'HX',\n",
       " 'ANTE',\n",
       " 'BIB',\n",
       " 'JRSH',\n",
       " 'SES',\n",
       " 'ALDX',\n",
       " 'MOGO']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get 50000 long sentences from 502 unique long sentences\n",
    "# then get 50000 short sentences with each containing 20 words\n",
    "\n",
    "np.random.seed(1993)\n",
    "\n",
    "ind = np.random.choice(len(total_list), n_sentence, replace=True)\n",
    "output_list = [get_similar(total_list[i], n_similar) for i in ind]\n",
    "\n",
    "print(len(output_list))\n",
    "output_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "2928\n"
     ]
    }
   ],
   "source": [
    "# generate training set of embedding\n",
    "\n",
    "output = [element for lis in output_list for element in lis]\n",
    "unique_stocks = set(output)\n",
    "print(len(output))\n",
    "print(len(unique_stocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = './Data/stocks_emb_train.txt'\n",
    "with open(out_dir, 'w', encoding='utf-8') as fout:\n",
    "        for word in output:\n",
    "            fout.write(word+' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use fastText to train\n",
    "\n",
    "cmd = \"./fasttext skipgram -epoch 5 -minCount 0 -dim 100 -thread 12 -ws 5 -neg 5 -input Data/stocks_emb_train.txt -output Data/stocks_emb 1>data/stocks_emb.log 2>&1\"\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True, shell=True)\n",
    "print(result.stdout)\n",
    "print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.deprecated.word2vec:Slow version of gensim.models.deprecated.word2vec is being used\n"
     ]
    }
   ],
   "source": [
    "# get .w2vec for next step\n",
    "%run generate_d2gpo_embedding.py ./Data/stocks_emb.bin ./Data/stocks_symbols.vocab ./Data/stocks_emb.vec ./Data/stocks_emb.w2vec\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
