{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0wmt14.en-fr.fconv-py/\n",
      "wmt14.en-fr.fconv-py/model.pt\n",
      " 99 1909M   99 1903M    0     0  9641k      0  0:03:22  0:03:22 --:--:--  9.8M  0  0:03:21  0:01:04  0:02:17  9.8MM:25 9780kwmt14.en-fr.fconv-py/dict.en.txt\n",
      "wmt14.en-fr.fconv-py/dict.fr.txt\n",
      "100 1909M  100 1909M    0     0  9642k      0  0:03:22  0:03:22 --:--:--  9.7M\n",
      "wmt14.en-fr.fconv-py/bpecodes\n",
      "wmt14.en-fr.fconv-py/README.md\n"
     ]
    }
   ],
   "source": [
    "#get the wmt14 model with English to French\n",
    "!curl https://dl.fbaipublicfiles.com/fairseq/models/wmt14.v2.en-fr.fconv-py.tar.bz2 | tar xvjf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(align_suffix=None, alignfile=None, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='fairseq/data-bin/iwslt14.tokenized.de-en', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', memory_efficient_fp16=False, min_loss_scale=0.0001, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=1, source_lang='de', srcdict=None, target_lang='en', task='translation', tensorboard_logdir='', testpref='fairseq/examples/translation/iwslt14.tokenized.de-en/test', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='fairseq/examples/translation/iwslt14.tokenized.de-en/train', user_dir=None, validpref='fairseq/examples/translation/iwslt14.tokenized.de-en/valid', workers=1)\n",
      "| [de] Dictionary: 8847 types\n",
      "| [de] fairseq/examples/translation/iwslt14.tokenized.de-en/train.de: 160239 sents, 4035591 tokens, 0.0% replaced by <unk>\n",
      "| [de] Dictionary: 8847 types\n",
      "| [de] fairseq/examples/translation/iwslt14.tokenized.de-en/valid.de: 7283 sents, 182592 tokens, 0.0192% replaced by <unk>\n",
      "| [de] Dictionary: 8847 types\n",
      "| [de] fairseq/examples/translation/iwslt14.tokenized.de-en/test.de: 6750 sents, 161838 tokens, 0.0636% replaced by <unk>\n",
      "| [en] Dictionary: 6631 types\n",
      "| [en] fairseq/examples/translation/iwslt14.tokenized.de-en/train.en: 160239 sents, 3949114 tokens, 0.0% replaced by <unk>\n",
      "| [en] Dictionary: 6631 types\n",
      "| [en] fairseq/examples/translation/iwslt14.tokenized.de-en/valid.en: 7283 sents, 178622 tokens, 0.00448% replaced by <unk>\n",
      "| [en] Dictionary: 6631 types\n",
      "| [en] fairseq/examples/translation/iwslt14.tokenized.de-en/test.en: 6750 sents, 156928 tokens, 0.00892% replaced by <unk>\n",
      "| Wrote preprocessed data to fairseq/data-bin/iwslt14.tokenized.de-en\n"
     ]
    }
   ],
   "source": [
    "#Use the Facebook AI Research Package to preprocess the lanaguage data into tokenlized data with BPE\n",
    "!fairseq-preprocess --source-lang de --target-lang en \\\n",
    "    --trainpref fairseq/examples/translation/iwslt14.tokenized.de-en/train --validpref fairseq/examples/translation/iwslt14.tokenized.de-en/valid --testpref fairseq/examples/translation/iwslt14.tokenized.de-en/test \\\n",
    "    --destdir fairseq/data-bin/iwslt14.tokenized.de-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dir for storing the checkpoints\n",
    "!mkdir -p checkpoints/fconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(arch='fconv_iwslt_de_en', best_checkpoint_metric='loss', bpe=None, bucket_cap_mb=25, clip_norm=0.1, cpu=False, criterion='cross_entropy', curriculum=0, data='fairseq/data-bin/iwslt14.tokenized.de-en', dataset_impl=None, ddp_backend='c10d', decoder_attention='True', decoder_embed_dim=256, decoder_embed_path=None, decoder_layers='[(256, 3)] * 3', decoder_out_embed_dim=256, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.2, empty_cache_freq=0, encoder_embed_dim=256, encoder_embed_path=None, encoder_layers='[(256, 3)] * 4', fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_interval_updates=-1, keep_last_epochs=-1, lazy_load=False, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[0.25], lr_scheduler='fixed', lr_shrink=0.1, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=4000, max_tokens_valid=4000, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, momentum=0.99, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, num_workers=1, optimizer='nag', optimizer_overrides='{}', raw_text=False, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints/fconv', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, share_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, source_lang=None, target_lang=None, task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=0, weight_decay=0.0)\n",
      "| [de] dictionary: 8848 types\n",
      "| [en] dictionary: 6632 types\n",
      "| loaded 7283 examples from: fairseq/data-bin/iwslt14.tokenized.de-en/valid.de-en.de\n",
      "| loaded 7283 examples from: fairseq/data-bin/iwslt14.tokenized.de-en/valid.de-en.en\n",
      "| fairseq/data-bin/iwslt14.tokenized.de-en valid de-en 7283 examples\n",
      "FConvModel(\n",
      "  (encoder): FConvEncoder(\n",
      "    (embed_tokens): Embedding(8848, 256, padding_idx=1)\n",
      "    (embed_positions): LearnedPositionalEmbedding(1024, 256, padding_idx=1)\n",
      "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (projections): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "      (3): None\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
      "      (1): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
      "      (2): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
      "      (3): ConvTBC(256, 512, kernel_size=(3,), padding=(1,))\n",
      "    )\n",
      "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      "  (decoder): FConvDecoder(\n",
      "    (embed_tokens): Embedding(6632, 256, padding_idx=1)\n",
      "    (embed_positions): LearnedPositionalEmbedding(1024, 256, padding_idx=1)\n",
      "    (fc1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (projections): ModuleList(\n",
      "      (0): None\n",
      "      (1): None\n",
      "      (2): None\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): LinearizedConvolution(256, 512, kernel_size=(3,), padding=(2,))\n",
      "      (1): LinearizedConvolution(256, 512, kernel_size=(3,), padding=(2,))\n",
      "      (2): LinearizedConvolution(256, 512, kernel_size=(3,), padding=(2,))\n",
      "    )\n",
      "    (attention): ModuleList(\n",
      "      (0): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (out_projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (out_projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (2): AttentionLayer(\n",
      "        (in_projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (out_projection): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (fc3): Linear(in_features=256, out_features=6632, bias=True)\n",
      "  )\n",
      ")\n",
      "| model fconv_iwslt_de_en, criterion CrossEntropyCriterion\n",
      "| num. model params: 9618384 (num. trained: 9618384)\n",
      "| training on 1 GPUs\n",
      "| max tokens per GPU = 4000 and max sentences per GPU = None\n",
      "| no existing checkpoint found checkpoints/fconv/checkpoint_last.pt\n",
      "| loading train data for epoch 0\n",
      "| loaded 160239 examples from: fairseq/data-bin/iwslt14.tokenized.de-en/train.de-en.de\n",
      "| loaded 160239 examples from: fairseq/data-bin/iwslt14.tokenized.de-en/train.de-en.en\n",
      "| fairseq/data-bin/iwslt14.tokenized.de-en train de-en 160239 examples\n",
      "| epoch 001 | loss 7.550 | ppl 187.42 | wps 29532 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 1131 | lr 0.25 | gnorm 0.554 | clip 1.000 | oom 0.000 | wall 136 | train_wall 130\n",
      "| epoch 001 | valid on 'valid' subset | loss 5.952 | ppl 61.91 | num_updates 1131\n",
      "| saved checkpoint checkpoints/fconv/checkpoint1.pt (epoch 1 @ 1131 updates) (writing took 0.281156063079834 seconds)\n",
      "| epoch 002 | loss 5.535 | ppl 46.36 | wps 29485 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 2262 | lr 0.25 | gnorm 0.443 | clip 1.000 | oom 0.000 | wall 273 | train_wall 258\n",
      "| epoch 002 | valid on 'valid' subset | loss 4.682 | ppl 25.67 | num_updates 2262 | best_loss 4.68225\n",
      "| saved checkpoint checkpoints/fconv/checkpoint2.pt (epoch 2 @ 2262 updates) (writing took 1.1735594272613525 seconds)\n",
      "| epoch 003 | loss 4.665 | ppl 25.38 | wps 29437 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 3393 | lr 0.25 | gnorm 0.471 | clip 1.000 | oom 0.000 | wall 411 | train_wall 387\n",
      "| epoch 003 | valid on 'valid' subset | loss 4.141 | ppl 17.64 | num_updates 3393 | best_loss 4.14106\n",
      "| saved checkpoint checkpoints/fconv/checkpoint3.pt (epoch 3 @ 3393 updates) (writing took 0.849172830581665 seconds)\n",
      "| epoch 004 | loss 4.216 | ppl 18.58 | wps 29432 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 4524 | lr 0.25 | gnorm 0.451 | clip 1.000 | oom 0.000 | wall 549 | train_wall 516\n",
      "| epoch 004 | valid on 'valid' subset | loss 3.837 | ppl 14.29 | num_updates 4524 | best_loss 3.83653\n",
      "| saved checkpoint checkpoints/fconv/checkpoint4.pt (epoch 4 @ 4524 updates) (writing took 1.166616678237915 seconds)\n",
      "| epoch 005 | loss 3.942 | ppl 15.36 | wps 29390 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 5655 | lr 0.25 | gnorm 0.434 | clip 1.000 | oom 0.000 | wall 687 | train_wall 646\n",
      "| epoch 005 | valid on 'valid' subset | loss 3.618 | ppl 12.28 | num_updates 5655 | best_loss 3.61839\n",
      "| saved checkpoint checkpoints/fconv/checkpoint5.pt (epoch 5 @ 5655 updates) (writing took 0.7391743659973145 seconds)\n",
      "| epoch 006 | loss 3.754 | ppl 13.5 | wps 29359 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 6786 | lr 0.25 | gnorm 0.420 | clip 1.000 | oom 0.000 | wall 825 | train_wall 775\n",
      "| epoch 006 | valid on 'valid' subset | loss 3.510 | ppl 11.39 | num_updates 6786 | best_loss 3.51005\n",
      "| saved checkpoint checkpoints/fconv/checkpoint6.pt (epoch 6 @ 6786 updates) (writing took 1.2088775634765625 seconds)\n",
      "| epoch 007 | loss 3.615 | ppl 12.25 | wps 29349 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 7917 | lr 0.25 | gnorm 0.406 | clip 1.000 | oom 0.000 | wall 963 | train_wall 904\n",
      "| epoch 007 | valid on 'valid' subset | loss 3.397 | ppl 10.54 | num_updates 7917 | best_loss 3.39733\n",
      "| saved checkpoint checkpoints/fconv/checkpoint7.pt (epoch 7 @ 7917 updates) (writing took 0.7585768699645996 seconds)\n",
      "| epoch 008 | loss 3.495 | ppl 11.27 | wps 29354 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 9048 | lr 0.25 | gnorm 0.392 | clip 1.000 | oom 0.000 | wall 1101 | train_wall 1033\n",
      "| epoch 008 | valid on 'valid' subset | loss 3.300 | ppl 9.85 | num_updates 9048 | best_loss 3.29956\n",
      "| saved checkpoint checkpoints/fconv/checkpoint8.pt (epoch 8 @ 9048 updates) (writing took 1.262744426727295 seconds)\n",
      "| epoch 009 | loss 3.412 | ppl 10.65 | wps 29290 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 10179 | lr 0.25 | gnorm 0.386 | clip 1.000 | oom 0.000 | wall 1240 | train_wall 1163\n",
      "| epoch 009 | valid on 'valid' subset | loss 3.251 | ppl 9.52 | num_updates 10179 | best_loss 3.2512\n",
      "| saved checkpoint checkpoints/fconv/checkpoint9.pt (epoch 9 @ 10179 updates) (writing took 0.9568336009979248 seconds)\n",
      "| epoch 010 | loss 3.337 | ppl 10.1 | wps 29329 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 11310 | lr 0.25 | gnorm 0.374 | clip 1.000 | oom 0.000 | wall 1378 | train_wall 1292\n",
      "| epoch 010 | valid on 'valid' subset | loss 3.195 | ppl 9.16 | num_updates 11310 | best_loss 3.19525\n",
      "| saved checkpoint checkpoints/fconv/checkpoint10.pt (epoch 10 @ 11310 updates) (writing took 0.9420764446258545 seconds)\n",
      "| epoch 011 | loss 3.263 | ppl 9.6 | wps 29259 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 12441 | lr 0.25 | gnorm 0.365 | clip 1.000 | oom 0.000 | wall 1516 | train_wall 1421\n",
      "| epoch 011 | valid on 'valid' subset | loss 3.150 | ppl 8.87 | num_updates 12441 | best_loss 3.14965\n",
      "| saved checkpoint checkpoints/fconv/checkpoint11.pt (epoch 11 @ 12441 updates) (writing took 1.065582036972046 seconds)\n",
      "| epoch 012 | loss 3.200 | ppl 9.19 | wps 29419 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 13572 | lr 0.25 | gnorm 0.357 | clip 1.000 | oom 0.000 | wall 1654 | train_wall 1550\n",
      "| epoch 012 | valid on 'valid' subset | loss 3.120 | ppl 8.7 | num_updates 13572 | best_loss 3.12031\n",
      "| saved checkpoint checkpoints/fconv/checkpoint12.pt (epoch 12 @ 13572 updates) (writing took 1.2677786350250244 seconds)\n",
      "| epoch 013 | loss 3.150 | ppl 8.88 | wps 29496 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 14703 | lr 0.25 | gnorm 0.351 | clip 1.000 | oom 0.000 | wall 1792 | train_wall 1678\n",
      "| epoch 013 | valid on 'valid' subset | loss 3.084 | ppl 8.48 | num_updates 14703 | best_loss 3.08385\n",
      "| saved checkpoint checkpoints/fconv/checkpoint13.pt (epoch 13 @ 14703 updates) (writing took 0.7892413139343262 seconds)\n",
      "| epoch 014 | loss 3.109 | ppl 8.63 | wps 29408 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 15834 | lr 0.25 | gnorm 0.347 | clip 1.000 | oom 0.000 | wall 1930 | train_wall 1807\n",
      "| epoch 014 | valid on 'valid' subset | loss 3.059 | ppl 8.33 | num_updates 15834 | best_loss 3.05913\n",
      "| saved checkpoint checkpoints/fconv/checkpoint14.pt (epoch 14 @ 15834 updates) (writing took 1.2594268321990967 seconds)\n",
      "| epoch 015 | loss 3.068 | ppl 8.39 | wps 29477 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 16965 | lr 0.25 | gnorm 0.340 | clip 1.000 | oom 0.000 | wall 2068 | train_wall 1935\n",
      "| epoch 015 | valid on 'valid' subset | loss 3.040 | ppl 8.22 | num_updates 16965 | best_loss 3.03998\n",
      "| saved checkpoint checkpoints/fconv/checkpoint15.pt (epoch 15 @ 16965 updates) (writing took 0.3751842975616455 seconds)\n",
      "| epoch 016 | loss 3.033 | ppl 8.18 | wps 29402 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 18096 | lr 0.25 | gnorm 0.335 | clip 1.000 | oom 0.000 | wall 2205 | train_wall 2064\n",
      "| epoch 016 | valid on 'valid' subset | loss 3.003 | ppl 8.02 | num_updates 18096 | best_loss 3.00307\n",
      "| saved checkpoint checkpoints/fconv/checkpoint16.pt (epoch 16 @ 18096 updates) (writing took 0.3043856620788574 seconds)\n",
      "| epoch 017 | loss 2.995 | ppl 7.97 | wps 29441 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 19227 | lr 0.25 | gnorm 0.329 | clip 1.000 | oom 0.000 | wall 2342 | train_wall 2193\n",
      "| epoch 017 | valid on 'valid' subset | loss 2.999 | ppl 8 | num_updates 19227 | best_loss 2.99948\n",
      "| saved checkpoint checkpoints/fconv/checkpoint17.pt (epoch 17 @ 19227 updates) (writing took 0.3063981533050537 seconds)\n",
      "| epoch 018 | loss 2.969 | ppl 7.83 | wps 29483 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 20358 | lr 0.25 | gnorm 0.327 | clip 1.000 | oom 0.000 | wall 2479 | train_wall 2321\n",
      "| epoch 018 | valid on 'valid' subset | loss 2.977 | ppl 7.87 | num_updates 20358 | best_loss 2.97697\n",
      "| saved checkpoint checkpoints/fconv/checkpoint18.pt (epoch 18 @ 20358 updates) (writing took 0.29975223541259766 seconds)\n",
      "| epoch 019 | loss 2.938 | ppl 7.66 | wps 29389 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 21489 | lr 0.25 | gnorm 0.320 | clip 1.000 | oom 0.000 | wall 2616 | train_wall 2449\n",
      "| epoch 019 | valid on 'valid' subset | loss 2.964 | ppl 7.8 | num_updates 21489 | best_loss 2.9635\n",
      "| saved checkpoint checkpoints/fconv/checkpoint19.pt (epoch 19 @ 21489 updates) (writing took 0.3057539463043213 seconds)\n",
      "| epoch 020 | loss 2.915 | ppl 7.54 | wps 29393 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 22620 | lr 0.25 | gnorm 0.319 | clip 1.000 | oom 0.000 | wall 2753 | train_wall 2578\n",
      "| epoch 020 | valid on 'valid' subset | loss 2.960 | ppl 7.78 | num_updates 22620 | best_loss 2.95976\n",
      "| saved checkpoint checkpoints/fconv/checkpoint20.pt (epoch 20 @ 22620 updates) (writing took 0.29324769973754883 seconds)\n",
      "| epoch 021 | loss 2.883 | ppl 7.38 | wps 29243 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 23751 | lr 0.25 | gnorm 0.311 | clip 1.000 | oom 0.000 | wall 2891 | train_wall 2707\n",
      "| epoch 021 | valid on 'valid' subset | loss 2.919 | ppl 7.56 | num_updates 23751 | best_loss 2.91909\n",
      "| saved checkpoint checkpoints/fconv/checkpoint21.pt (epoch 21 @ 23751 updates) (writing took 0.2968416213989258 seconds)\n",
      "| epoch 022 | loss 2.861 | ppl 7.26 | wps 29187 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 24882 | lr 0.25 | gnorm 0.310 | clip 1.000 | oom 0.000 | wall 3029 | train_wall 2836\n",
      "| epoch 022 | valid on 'valid' subset | loss 2.916 | ppl 7.55 | num_updates 24882 | best_loss 2.9156\n",
      "| saved checkpoint checkpoints/fconv/checkpoint22.pt (epoch 22 @ 24882 updates) (writing took 0.30074524879455566 seconds)\n",
      "| epoch 023 | loss 2.837 | ppl 7.15 | wps 29253 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 26013 | lr 0.25 | gnorm 0.306 | clip 1.000 | oom 0.000 | wall 3167 | train_wall 2965\n",
      "| epoch 023 | valid on 'valid' subset | loss 2.930 | ppl 7.62 | num_updates 26013 | best_loss 2.9156\n",
      "| saved checkpoint checkpoints/fconv/checkpoint23.pt (epoch 23 @ 26013 updates) (writing took 0.19327592849731445 seconds)\n",
      "| epoch 024 | loss 2.818 | ppl 7.05 | wps 29219 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 27144 | lr 0.25 | gnorm 0.303 | clip 1.000 | oom 0.000 | wall 3305 | train_wall 3094\n",
      "| epoch 024 | valid on 'valid' subset | loss 2.895 | ppl 7.44 | num_updates 27144 | best_loss 2.89469\n",
      "| saved checkpoint checkpoints/fconv/checkpoint24.pt (epoch 24 @ 27144 updates) (writing took 0.30406785011291504 seconds)\n",
      "| epoch 025 | loss 2.798 | ppl 6.96 | wps 29168 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 28275 | lr 0.25 | gnorm 0.301 | clip 1.000 | oom 0.000 | wall 3444 | train_wall 3223\n",
      "| epoch 025 | valid on 'valid' subset | loss 2.905 | ppl 7.49 | num_updates 28275 | best_loss 2.89469\n",
      "| saved checkpoint checkpoints/fconv/checkpoint25.pt (epoch 25 @ 28275 updates) (writing took 0.2939331531524658 seconds)\n",
      "| epoch 026 | loss 2.779 | ppl 6.87 | wps 29154 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 29406 | lr 0.25 | gnorm 0.297 | clip 1.000 | oom 0.000 | wall 3582 | train_wall 3352\n",
      "| epoch 026 | valid on 'valid' subset | loss 2.880 | ppl 7.36 | num_updates 29406 | best_loss 2.88033\n",
      "| saved checkpoint checkpoints/fconv/checkpoint26.pt (epoch 26 @ 29406 updates) (writing took 1.182826280593872 seconds)\n",
      "| epoch 027 | loss 2.756 | ppl 6.76 | wps 29139 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 30537 | lr 0.25 | gnorm 0.293 | clip 1.000 | oom 0.000 | wall 3721 | train_wall 3481\n",
      "| epoch 027 | valid on 'valid' subset | loss 2.895 | ppl 7.44 | num_updates 30537 | best_loss 2.88033\n",
      "| saved checkpoint checkpoints/fconv/checkpoint27.pt (epoch 27 @ 30537 updates) (writing took 0.3624086380004883 seconds)\n",
      "| epoch 028 | loss 2.746 | ppl 6.71 | wps 29175 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 31668 | lr 0.25 | gnorm 0.293 | clip 1.000 | oom 0.000 | wall 3860 | train_wall 3610\n",
      "| epoch 028 | valid on 'valid' subset | loss 2.863 | ppl 7.28 | num_updates 31668 | best_loss 2.86299\n",
      "| saved checkpoint checkpoints/fconv/checkpoint28.pt (epoch 28 @ 31668 updates) (writing took 1.1180942058563232 seconds)\n",
      "| epoch 029 | loss 2.731 | ppl 6.64 | wps 29173 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 32799 | lr 0.25 | gnorm 0.291 | clip 1.000 | oom 0.000 | wall 3999 | train_wall 3739\n",
      "| epoch 029 | valid on 'valid' subset | loss 2.853 | ppl 7.23 | num_updates 32799 | best_loss 2.85331\n",
      "| saved checkpoint checkpoints/fconv/checkpoint29.pt (epoch 29 @ 32799 updates) (writing took 0.4217824935913086 seconds)\n",
      "| epoch 030 | loss 2.714 | ppl 6.56 | wps 29086 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 33930 | lr 0.25 | gnorm 0.287 | clip 1.000 | oom 0.000 | wall 4138 | train_wall 3868\n",
      "| epoch 030 | valid on 'valid' subset | loss 2.855 | ppl 7.23 | num_updates 33930 | best_loss 2.85331\n",
      "| saved checkpoint checkpoints/fconv/checkpoint30.pt (epoch 30 @ 33930 updates) (writing took 0.43633317947387695 seconds)\n",
      "| epoch 031 | loss 2.702 | ppl 6.51 | wps 29064 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 35061 | lr 0.25 | gnorm 0.286 | clip 1.000 | oom 0.000 | wall 4277 | train_wall 3997\n",
      "| epoch 031 | valid on 'valid' subset | loss 2.837 | ppl 7.15 | num_updates 35061 | best_loss 2.83711\n",
      "| saved checkpoint checkpoints/fconv/checkpoint31.pt (epoch 31 @ 35061 updates) (writing took 0.35439038276672363 seconds)\n",
      "| epoch 032 | loss 2.686 | ppl 6.43 | wps 29144 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 36192 | lr 0.25 | gnorm 0.283 | clip 1.000 | oom 0.000 | wall 4415 | train_wall 4126\n",
      "| epoch 032 | valid on 'valid' subset | loss 2.869 | ppl 7.3 | num_updates 36192 | best_loss 2.83711\n",
      "| saved checkpoint checkpoints/fconv/checkpoint32.pt (epoch 32 @ 36192 updates) (writing took 0.2035691738128662 seconds)\n",
      "| epoch 033 | loss 2.674 | ppl 6.38 | wps 29066 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 37323 | lr 0.25 | gnorm 0.281 | clip 1.000 | oom 0.000 | wall 4554 | train_wall 4255\n",
      "| epoch 033 | valid on 'valid' subset | loss 2.848 | ppl 7.2 | num_updates 37323 | best_loss 2.83711\n",
      "| saved checkpoint checkpoints/fconv/checkpoint33.pt (epoch 33 @ 37323 updates) (writing took 0.5357046127319336 seconds)\n",
      "| epoch 034 | loss 2.661 | ppl 6.32 | wps 29103 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 38454 | lr 0.25 | gnorm 0.279 | clip 1.000 | oom 0.000 | wall 4693 | train_wall 4384\n",
      "| epoch 034 | valid on 'valid' subset | loss 2.846 | ppl 7.19 | num_updates 38454 | best_loss 2.83711\n",
      "| saved checkpoint checkpoints/fconv/checkpoint34.pt (epoch 34 @ 38454 updates) (writing took 0.21863675117492676 seconds)\n",
      "| epoch 035 | loss 2.650 | ppl 6.28 | wps 29057 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 39585 | lr 0.25 | gnorm 0.278 | clip 1.000 | oom 0.000 | wall 4831 | train_wall 4514\n",
      "| epoch 035 | valid on 'valid' subset | loss 2.816 | ppl 7.04 | num_updates 39585 | best_loss 2.81605\n",
      "| saved checkpoint checkpoints/fconv/checkpoint35.pt (epoch 35 @ 39585 updates) (writing took 0.76200270652771 seconds)\n",
      "| epoch 036 | loss 2.636 | ppl 6.22 | wps 29055 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 40716 | lr 0.25 | gnorm 0.275 | clip 1.000 | oom 0.000 | wall 4971 | train_wall 4643\n",
      "| epoch 036 | valid on 'valid' subset | loss 2.812 | ppl 7.02 | num_updates 40716 | best_loss 2.81221\n",
      "| saved checkpoint checkpoints/fconv/checkpoint36.pt (epoch 36 @ 40716 updates) (writing took 0.88301682472229 seconds)\n",
      "| epoch 037 | loss 2.623 | ppl 6.16 | wps 29063 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 41847 | lr 0.25 | gnorm 0.274 | clip 1.000 | oom 0.000 | wall 5110 | train_wall 4772\n",
      "| epoch 037 | valid on 'valid' subset | loss 2.817 | ppl 7.05 | num_updates 41847 | best_loss 2.81221\n",
      "| saved checkpoint checkpoints/fconv/checkpoint37.pt (epoch 37 @ 41847 updates) (writing took 0.26909565925598145 seconds)\n",
      "| epoch 038 | loss 2.618 | ppl 6.14 | wps 29047 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 42978 | lr 0.25 | gnorm 0.273 | clip 1.000 | oom 0.000 | wall 5249 | train_wall 4901\n",
      "| epoch 038 | valid on 'valid' subset | loss 2.826 | ppl 7.09 | num_updates 42978 | best_loss 2.81221\n",
      "| saved checkpoint checkpoints/fconv/checkpoint38.pt (epoch 38 @ 42978 updates) (writing took 0.19405579566955566 seconds)\n",
      "| epoch 039 | loss 2.604 | ppl 6.08 | wps 28990 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 44109 | lr 0.25 | gnorm 0.270 | clip 1.000 | oom 0.000 | wall 5388 | train_wall 5030\n",
      "| epoch 039 | valid on 'valid' subset | loss 2.796 | ppl 6.94 | num_updates 44109 | best_loss 2.79577\n",
      "| saved checkpoint checkpoints/fconv/checkpoint39.pt (epoch 39 @ 44109 updates) (writing took 0.7350594997406006 seconds)\n",
      "| epoch 040 | loss 2.598 | ppl 6.05 | wps 29009 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 45240 | lr 0.25 | gnorm 0.269 | clip 1.000 | oom 0.000 | wall 5528 | train_wall 5159\n",
      "| epoch 040 | valid on 'valid' subset | loss 2.803 | ppl 6.98 | num_updates 45240 | best_loss 2.79577\n",
      "| saved checkpoint checkpoints/fconv/checkpoint40.pt (epoch 40 @ 45240 updates) (writing took 0.19526457786560059 seconds)\n",
      "| epoch 041 | loss 2.586 | ppl 6.01 | wps 29016 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 46371 | lr 0.25 | gnorm 0.268 | clip 1.000 | oom 0.000 | wall 5666 | train_wall 5288\n",
      "| epoch 041 | valid on 'valid' subset | loss 2.805 | ppl 6.99 | num_updates 46371 | best_loss 2.79577\n",
      "| saved checkpoint checkpoints/fconv/checkpoint41.pt (epoch 41 @ 46371 updates) (writing took 0.19962382316589355 seconds)\n",
      "| epoch 042 | loss 2.574 | ppl 5.95 | wps 28985 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 47502 | lr 0.25 | gnorm 0.264 | clip 1.000 | oom 0.000 | wall 5806 | train_wall 5417\n",
      "| epoch 042 | valid on 'valid' subset | loss 2.805 | ppl 6.99 | num_updates 47502 | best_loss 2.79577\n",
      "| saved checkpoint checkpoints/fconv/checkpoint42.pt (epoch 42 @ 47502 updates) (writing took 0.19359064102172852 seconds)\n",
      "| epoch 043 | loss 2.565 | ppl 5.92 | wps 29060 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 48633 | lr 0.25 | gnorm 0.264 | clip 1.000 | oom 0.000 | wall 5944 | train_wall 5546\n",
      "| epoch 043 | valid on 'valid' subset | loss 2.799 | ppl 6.96 | num_updates 48633 | best_loss 2.79577\n",
      "| saved checkpoint checkpoints/fconv/checkpoint43.pt (epoch 43 @ 48633 updates) (writing took 0.18507027626037598 seconds)\n",
      "| epoch 044 | loss 2.557 | ppl 5.89 | wps 28986 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 49764 | lr 0.25 | gnorm 0.263 | clip 1.000 | oom 0.000 | wall 6083 | train_wall 5675\n",
      "| epoch 044 | valid on 'valid' subset | loss 2.793 | ppl 6.93 | num_updates 49764 | best_loss 2.79256\n",
      "| saved checkpoint checkpoints/fconv/checkpoint44.pt (epoch 44 @ 49764 updates) (writing took 0.29955315589904785 seconds)\n",
      "| epoch 045 | loss 2.551 | ppl 5.86 | wps 29058 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 50895 | lr 0.25 | gnorm 0.262 | clip 1.000 | oom 0.000 | wall 6222 | train_wall 5804\n",
      "| epoch 045 | valid on 'valid' subset | loss 2.791 | ppl 6.92 | num_updates 50895 | best_loss 2.79106\n",
      "| saved checkpoint checkpoints/fconv/checkpoint45.pt (epoch 45 @ 50895 updates) (writing took 0.29302191734313965 seconds)\n",
      "| epoch 046 | loss 2.539 | ppl 5.81 | wps 29053 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 52026 | lr 0.25 | gnorm 0.259 | clip 1.000 | oom 0.000 | wall 6361 | train_wall 5933\n",
      "| epoch 046 | valid on 'valid' subset | loss 2.787 | ppl 6.9 | num_updates 52026 | best_loss 2.78722\n",
      "| saved checkpoint checkpoints/fconv/checkpoint46.pt (epoch 46 @ 52026 updates) (writing took 0.3000972270965576 seconds)\n",
      "| epoch 047 | loss 2.529 | ppl 5.77 | wps 28991 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 53157 | lr 0.25 | gnorm 0.259 | clip 1.000 | oom 0.000 | wall 6500 | train_wall 6061\n",
      "| epoch 047 | valid on 'valid' subset | loss 2.771 | ppl 6.83 | num_updates 53157 | best_loss 2.77095\n",
      "| saved checkpoint checkpoints/fconv/checkpoint47.pt (epoch 47 @ 53157 updates) (writing took 0.2989833354949951 seconds)\n",
      "| epoch 048 | loss 2.521 | ppl 5.74 | wps 28984 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 54288 | lr 0.25 | gnorm 0.257 | clip 1.000 | oom 0.000 | wall 6639 | train_wall 6190\n",
      "| epoch 048 | valid on 'valid' subset | loss 2.789 | ppl 6.91 | num_updates 54288 | best_loss 2.77095\n",
      "| saved checkpoint checkpoints/fconv/checkpoint48.pt (epoch 48 @ 54288 updates) (writing took 0.1912548542022705 seconds)\n",
      "| epoch 049 | loss 2.514 | ppl 5.71 | wps 29004 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 55419 | lr 0.25 | gnorm 0.257 | clip 1.000 | oom 0.000 | wall 6778 | train_wall 6319\n",
      "| epoch 049 | valid on 'valid' subset | loss 2.781 | ppl 6.87 | num_updates 55419 | best_loss 2.77095\n",
      "| saved checkpoint checkpoints/fconv/checkpoint49.pt (epoch 49 @ 55419 updates) (writing took 0.1959974765777588 seconds)\n",
      "| epoch 050 | loss 2.510 | ppl 5.7 | wps 28953 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 56550 | lr 0.25 | gnorm 0.256 | clip 1.000 | oom 0.000 | wall 6918 | train_wall 6448\n",
      "| epoch 050 | valid on 'valid' subset | loss 2.781 | ppl 6.87 | num_updates 56550 | best_loss 2.77095\n",
      "| saved checkpoint checkpoints/fconv/checkpoint50.pt (epoch 50 @ 56550 updates) (writing took 0.1977074146270752 seconds)\n",
      "| epoch 051 | loss 2.503 | ppl 5.67 | wps 29020 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 57681 | lr 0.25 | gnorm 0.255 | clip 1.000 | oom 0.000 | wall 7056 | train_wall 6577\n",
      "| epoch 051 | valid on 'valid' subset | loss 2.788 | ppl 6.91 | num_updates 57681 | best_loss 2.77095\n",
      "| saved checkpoint checkpoints/fconv/checkpoint51.pt (epoch 51 @ 57681 updates) (writing took 0.19384264945983887 seconds)\n",
      "| epoch 052 | loss 2.493 | ppl 5.63 | wps 28965 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 58812 | lr 0.25 | gnorm 0.253 | clip 1.000 | oom 0.000 | wall 7196 | train_wall 6706\n",
      "| epoch 052 | valid on 'valid' subset | loss 2.769 | ppl 6.81 | num_updates 58812 | best_loss 2.76858\n",
      "| saved checkpoint checkpoints/fconv/checkpoint52.pt (epoch 52 @ 58812 updates) (writing took 0.30214953422546387 seconds)\n",
      "| epoch 053 | loss 2.489 | ppl 5.61 | wps 28998 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 59943 | lr 0.25 | gnorm 0.253 | clip 1.000 | oom 0.000 | wall 7335 | train_wall 6835\n",
      "| epoch 053 | valid on 'valid' subset | loss 2.781 | ppl 6.87 | num_updates 59943 | best_loss 2.76858\n",
      "| saved checkpoint checkpoints/fconv/checkpoint53.pt (epoch 53 @ 59943 updates) (writing took 0.19098758697509766 seconds)\n",
      "| epoch 054 | loss 2.482 | ppl 5.59 | wps 29006 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 61074 | lr 0.25 | gnorm 0.251 | clip 1.000 | oom 0.000 | wall 7474 | train_wall 6963\n",
      "| epoch 054 | valid on 'valid' subset | loss 2.780 | ppl 6.87 | num_updates 61074 | best_loss 2.76858\n",
      "| saved checkpoint checkpoints/fconv/checkpoint54.pt (epoch 54 @ 61074 updates) (writing took 0.18922209739685059 seconds)\n",
      "| epoch 055 | loss 2.474 | ppl 5.56 | wps 29083 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 62205 | lr 0.25 | gnorm 0.250 | clip 1.000 | oom 0.000 | wall 7612 | train_wall 7092\n",
      "| epoch 055 | valid on 'valid' subset | loss 2.772 | ppl 6.83 | num_updates 62205 | best_loss 2.76858\n",
      "| saved checkpoint checkpoints/fconv/checkpoint55.pt (epoch 55 @ 62205 updates) (writing took 0.19312262535095215 seconds)\n",
      "| epoch 056 | loss 2.469 | ppl 5.54 | wps 29100 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 63336 | lr 0.25 | gnorm 0.249 | clip 1.000 | oom 0.000 | wall 7751 | train_wall 7219\n",
      "| epoch 056 | valid on 'valid' subset | loss 2.762 | ppl 6.78 | num_updates 63336 | best_loss 2.76172\n",
      "| saved checkpoint checkpoints/fconv/checkpoint56.pt (epoch 56 @ 63336 updates) (writing took 0.30419230461120605 seconds)\n",
      "| epoch 057 | loss 2.465 | ppl 5.52 | wps 28938 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 64467 | lr 0.25 | gnorm 0.249 | clip 1.000 | oom 0.000 | wall 7890 | train_wall 7348\n",
      "| epoch 057 | valid on 'valid' subset | loss 2.775 | ppl 6.85 | num_updates 64467 | best_loss 2.76172\n",
      "| saved checkpoint checkpoints/fconv/checkpoint57.pt (epoch 57 @ 64467 updates) (writing took 0.19935226440429688 seconds)\n",
      "| epoch 058 | loss 2.453 | ppl 5.48 | wps 28873 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 65598 | lr 0.25 | gnorm 0.246 | clip 1.000 | oom 0.000 | wall 8030 | train_wall 7477\n",
      "| epoch 058 | valid on 'valid' subset | loss 2.757 | ppl 6.76 | num_updates 65598 | best_loss 2.75706\n",
      "| saved checkpoint checkpoints/fconv/checkpoint58.pt (epoch 58 @ 65598 updates) (writing took 0.2959859371185303 seconds)\n",
      "| epoch 059 | loss 2.451 | ppl 5.47 | wps 28895 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 66729 | lr 0.25 | gnorm 0.247 | clip 1.000 | oom 0.000 | wall 8170 | train_wall 7606\n",
      "| epoch 059 | valid on 'valid' subset | loss 2.772 | ppl 6.83 | num_updates 66729 | best_loss 2.75706\n",
      "| saved checkpoint checkpoints/fconv/checkpoint59.pt (epoch 59 @ 66729 updates) (writing took 0.19521713256835938 seconds)\n",
      "| epoch 060 | loss 2.445 | ppl 5.45 | wps 28897 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 67860 | lr 0.25 | gnorm 0.246 | clip 1.000 | oom 0.000 | wall 8309 | train_wall 7735\n",
      "| epoch 060 | valid on 'valid' subset | loss 2.784 | ppl 6.89 | num_updates 67860 | best_loss 2.75706\n",
      "| saved checkpoint checkpoints/fconv/checkpoint60.pt (epoch 60 @ 67860 updates) (writing took 0.20427823066711426 seconds)\n",
      "| epoch 061 | loss 2.443 | ppl 5.44 | wps 28841 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 68991 | lr 0.25 | gnorm 0.246 | clip 1.000 | oom 0.000 | wall 8449 | train_wall 7865\n",
      "| epoch 061 | valid on 'valid' subset | loss 2.775 | ppl 6.85 | num_updates 68991 | best_loss 2.75706\n",
      "| saved checkpoint checkpoints/fconv/checkpoint61.pt (epoch 61 @ 68991 updates) (writing took 0.5005652904510498 seconds)\n",
      "| epoch 062 | loss 2.432 | ppl 5.4 | wps 25654 | ups 7 | wpb 3491.701 | bsz 141.679 | num_updates 70122 | lr 0.25 | gnorm 0.243 | clip 1.000 | oom 0.000 | wall 8606 | train_wall 8009\n",
      "| epoch 062 | valid on 'valid' subset | loss 2.762 | ppl 6.78 | num_updates 70122 | best_loss 2.75706\n",
      "| saved checkpoint checkpoints/fconv/checkpoint62.pt (epoch 62 @ 70122 updates) (writing took 0.3323493003845215 seconds)\n",
      "| epoch 063 | loss 2.430 | ppl 5.39 | wps 28759 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 71253 | lr 0.25 | gnorm 0.244 | clip 1.000 | oom 0.000 | wall 8747 | train_wall 8138\n",
      "| epoch 063 | valid on 'valid' subset | loss 2.740 | ppl 6.68 | num_updates 71253 | best_loss 2.74042\n",
      "| saved checkpoint checkpoints/fconv/checkpoint63.pt (epoch 63 @ 71253 updates) (writing took 0.910292387008667 seconds)\n",
      "| epoch 064 | loss 2.421 | ppl 5.36 | wps 28863 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 72384 | lr 0.25 | gnorm 0.242 | clip 1.000 | oom 0.000 | wall 8887 | train_wall 8267\n",
      "| epoch 064 | valid on 'valid' subset | loss 2.758 | ppl 6.76 | num_updates 72384 | best_loss 2.74042\n",
      "| saved checkpoint checkpoints/fconv/checkpoint64.pt (epoch 64 @ 72384 updates) (writing took 0.20409321784973145 seconds)\n",
      "| epoch 065 | loss 2.419 | ppl 5.35 | wps 28766 | ups 8 | wpb 3491.701 | bsz 141.679 | num_updates 73515 | lr 0.25 | gnorm 0.242 | clip 1.000 | oom 0.000 | wall 9028 | train_wall 8396\n",
      "| epoch 065 | valid on 'valid' subset | loss 2.753 | ppl 6.74 | num_updates 73515 | best_loss 2.74042\n",
      "| saved checkpoint checkpoints/fconv/checkpoint65.pt (epoch 65 @ 73515 updates) (writing took 0.252957820892334 seconds)\n",
      "| epoch 066:  12%| | 134/1131 [00:16<02:04,  8.02it/s, loss=2.289, ppl=4.89, wps^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/im_wutian/.local/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/im_wutian/.local/lib/python3.7/site-packages/fairseq_cli/train.py\", line 333, in cli_main\n",
      "    main(args)\n",
      "  File \"/home/im_wutian/.local/lib/python3.7/site-packages/fairseq_cli/train.py\", line 86, in main\n",
      "    train(args, trainer, task, epoch_itr)\n",
      "  File \"/home/im_wutian/.local/lib/python3.7/site-packages/fairseq_cli/train.py\", line 127, in train\n",
      "    log_output = trainer.train_step(samples)\n",
      "  File \"/home/im_wutian/.local/lib/python3.7/site-packages/fairseq/trainer.py\", line 330, in train_step\n",
      "    sample, self.model, self.criterion, self.optimizer, ignore_grad\n",
      "  File \"/home/im_wutian/.local/lib/python3.7/site-packages/fairseq/tasks/fairseq_task.py\", line 254, in train_step\n",
      "    optimizer.backward(loss)\n",
      "  File \"/home/im_wutian/.local/lib/python3.7/site-packages/fairseq/optim/fairseq_optimizer.py\", line 81, in backward\n",
      "    loss.backward()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\", line 195, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Train the model using google cloud platform with K80 GPU\n",
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train fairseq/data-bin/iwslt14.tokenized.de-en \\\n",
    "    --lr 0.25 --clip-norm 0.1 --dropout 0.2 --max-tokens 4000 \\\n",
    "    --arch fconv_iwslt_de_en --save-dir checkpoints/fconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
